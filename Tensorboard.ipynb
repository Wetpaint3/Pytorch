{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0308e925e2e4fa3a757dd065407b14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab6a5f9b7c140c193db8d50e9a9f706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03282b47bffd4b639af2d0ae2707bf97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152b17ade9d6406db71cdb52e037c66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1587428266983/work/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_preds = torch.cat(class_preds)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_preds,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
